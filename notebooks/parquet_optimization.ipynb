{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format optimization parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: spark-submit [options] <app jar | python file | R file> [app arguments]\n",
      "Usage: spark-submit --kill [submission ID] --master [spark://...]\n",
      "Usage: spark-submit --status [submission ID] --master [spark://...]\n",
      "Usage: spark-submit run-example [options] example-class [example args]\n",
      "\n",
      "Options:\n",
      "  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,\n",
      "                              k8s://https://host:port, or local (Default: local[*]).\n",
      "  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally (\"client\") or\n",
      "                              on one of the worker machines inside the cluster (\"cluster\")\n",
      "                              (Default: client).\n",
      "  --class CLASS_NAME          Your application's main class (for Java / Scala apps).\n",
      "  --name NAME                 A name of your application.\n",
      "  --jars JARS                 Comma-separated list of jars to include on the driver\n",
      "                              and executor classpaths.\n",
      "  --packages                  Comma-separated list of maven coordinates of jars to include\n",
      "                              on the driver and executor classpaths. Will search the local\n",
      "                              maven repo, then maven central and any additional remote\n",
      "                              repositories given by --repositories. The format for the\n",
      "                              coordinates should be groupId:artifactId:version.\n",
      "  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while\n",
      "                              resolving the dependencies provided in --packages to avoid\n",
      "                              dependency conflicts.\n",
      "  --repositories              Comma-separated list of additional remote repositories to\n",
      "                              search for the maven coordinates given with --packages.\n",
      "  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place\n",
      "                              on the PYTHONPATH for Python apps.\n",
      "  --files FILES               Comma-separated list of files to be placed in the working\n",
      "                              directory of each executor. File paths of these files\n",
      "                              in executors can be accessed via SparkFiles.get(fileName).\n",
      "\n",
      "  --conf, -c PROP=VALUE       Arbitrary Spark configuration property.\n",
      "  --properties-file FILE      Path to a file from which to load extra properties. If not\n",
      "                              specified, this will look for conf/spark-defaults.conf.\n",
      "\n",
      "  --driver-memory MEM         Memory for driver (e.g. 1000M, 2G) (Default: 1024M).\n",
      "  --driver-java-options       Extra Java options to pass to the driver.\n",
      "  --driver-library-path       Extra library path entries to pass to the driver.\n",
      "  --driver-class-path         Extra class path entries to pass to the driver. Note that\n",
      "                              jars added with --jars are automatically included in the\n",
      "                              classpath.\n",
      "\n",
      "  --executor-memory MEM       Memory per executor (e.g. 1000M, 2G) (Default: 1G).\n",
      "\n",
      "  --proxy-user NAME           User to impersonate when submitting the application.\n",
      "                              This argument does not work with --principal / --keytab.\n",
      "\n",
      "  --help, -h                  Show this help message and exit.\n",
      "  --verbose, -v               Print additional debug output.\n",
      "  --version,                  Print the version of current Spark.\n",
      "\n",
      " Cluster deploy mode only:\n",
      "  --driver-cores NUM          Number of cores used by the driver, only in cluster mode\n",
      "                              (Default: 1).\n",
      "\n",
      " Spark standalone or Mesos with cluster deploy mode only:\n",
      "  --supervise                 If given, restarts the driver on failure.\n",
      "\n",
      " Spark standalone, Mesos or K8s with cluster deploy mode only:\n",
      "  --kill SUBMISSION_ID        If given, kills the driver specified.\n",
      "  --status SUBMISSION_ID      If given, requests the status of the driver specified.\n",
      "\n",
      " Spark standalone, Mesos and Kubernetes only:\n",
      "  --total-executor-cores NUM  Total cores for all executors.\n",
      "\n",
      " Spark standalone, YARN and Kubernetes only:\n",
      "  --executor-cores NUM        Number of cores used by each executor. (Default: 1 in\n",
      "                              YARN and K8S modes, or all available cores on the worker\n",
      "                              in standalone mode).\n",
      "\n",
      " Spark on YARN and Kubernetes only:\n",
      "  --num-executors NUM         Number of executors to launch (Default: 2).\n",
      "                              If dynamic allocation is enabled, the initial number of\n",
      "                              executors will be at least NUM.\n",
      "  --principal PRINCIPAL       Principal to be used to login to KDC.\n",
      "  --keytab KEYTAB             The full path to the file that contains the keytab for the\n",
      "                              principal specified above.\n",
      "\n",
      " Spark on YARN only:\n",
      "  --queue QUEUE_NAME          The YARN queue to submit to (Default: \"default\").\n",
      "  --archives ARCHIVES         Comma separated list of archives to be extracted into the\n",
      "                              working directory of each executor.\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "! /opt/spark/bin/spark-submit --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Key': 'pengfei/pengfei_test',\n",
       " 'name': 'pengfei/pengfei_test',\n",
       " 'type': 'directory',\n",
       " 'Size': 0,\n",
       " 'size': 0,\n",
       " 'StorageClass': 'DIRECTORY'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import s3fs\n",
    "endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint})\n",
    "event_log_path=\"pengfei/spark-history\"\n",
    "\n",
    "fs.touch('s3://'+event_log_path+'/.keep')\n",
    "fs.info('pengfei/pengfei_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "       .builder.master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "       .appName(\"Python Spark SQL basic example\") \\\n",
    "       .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:master\") \\\n",
    "       .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "       .config(\"spark.executor.instances\", \"5\") \\\n",
    "       .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "       .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "       .config(\"spark.eventLog.dir\",\"s3a://\"+event_log_path) \\\n",
    "       .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                      READY   STATUS      RESTARTS   AGE\n",
      "deleting-pods-with-completed-status-1614956400-xwz65      0/1     Completed   0          16m\n",
      "jupyter-1614950554-79cc9cbb97-tvlp4                       1/1     Running     0          113m\n",
      "python-spark-sql-basic-example-a6b8a9780296bb96-exec-69   0/1     Error       0          2m39s\n",
      "python-spark-sql-basic-example-a6b8a9780296bb96-exec-70   0/1     Error       0          2m39s\n",
      "python-spark-sql-basic-example-a6b8a9780296bb96-exec-71   1/1     Running     0          2m9s\n",
      "python-spark-sql-basic-example-a6b8a9780296bb96-exec-72   1/1     Running     0          2m9s\n",
      "python-spark-sql-basic-example-a6b8a9780296bb96-exec-73   1/1     Running     0          2m9s\n",
      "ubuntu-1612965548-79c9567b44-nhs9p                        1/1     Running     0          23d\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"s3a://pengfei/sspcloud-demo/data_format/Fire_Department_Calls_for_Service.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType\n",
    "\n",
    "fireSchema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "                     StructField('UnitID', StringType(), True),\n",
    "                     StructField('IncidentNumber', IntegerType(), True),\n",
    "                     StructField('CallType', StringType(), True),                  \n",
    "                     StructField('CallDate', StringType(), True),       \n",
    "                     StructField('WatchDate', StringType(), True),       \n",
    "                     StructField('ReceivedDtTm', StringType(), True),       \n",
    "                     StructField('EntryDtTm', StringType(), True),       \n",
    "                     StructField('DispatchDtTm', StringType(), True),       \n",
    "                     StructField('ResponseDtTm', StringType(), True),       \n",
    "                     StructField('OnSceneDtTm', StringType(), True),       \n",
    "                     StructField('TransportDtTm', StringType(), True),                  \n",
    "                     StructField('HospitalDtTm', StringType(), True),       \n",
    "                     StructField('CallFinalDisposition', StringType(), True),       \n",
    "                     StructField('AvailableDtTm', StringType(), True),       \n",
    "                     StructField('Address', StringType(), True),       \n",
    "                     StructField('City', StringType(), True),       \n",
    "                     StructField('ZipcodeofIncident', IntegerType(), True),       \n",
    "                     StructField('Battalion', StringType(), True),                 \n",
    "                     StructField('StationArea', StringType(), True),       \n",
    "                     StructField('Box', StringType(), True),       \n",
    "                     StructField('OriginalPriority', StringType(), True),       \n",
    "                     StructField('Priority', StringType(), True),       \n",
    "                     StructField('FinalPriority', IntegerType(), True),       \n",
    "                     StructField('ALSUnit', BooleanType(), True),       \n",
    "                     StructField('CallTypeGroup', StringType(), True),\n",
    "                     StructField('NumberofAlarms', IntegerType(), True),\n",
    "                     StructField('UnitType', StringType(), True),\n",
    "                     StructField('Unitsequenceincalldispatch', IntegerType(), True),\n",
    "                     StructField('FirePreventionDistrict', StringType(), True),\n",
    "                     StructField('SupervisorDistrict', StringType(), True),\n",
    "                     StructField('NeighborhoodDistrict', StringType(), True),\n",
    "                     StructField('Location', StringType(), True),\n",
    "                     StructField('RowID', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(delimiter=',').schema(fireSchema).csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+------------+----+-----------------+--------+-------------+-------+---------------+--------------+---------+--------------------------+----------------------+-------------------+--------------------+-------------+--------------------+\n",
      "|CallNumber| UnitID|IncidentNumber|            CallType|  CallDate| WatchDate|        ReceivedDtTm|           EntryDtTm|        DispatchDtTm|        ResponseDtTm|         OnSceneDtTm| TransportDtTm| HospitalDtTm|CallFinalDisposition|       AvailableDtTm|             Address|         City|ZipcodeofIncident|Battalion| StationArea| Box| OriginalPriority|Priority|FinalPriority|ALSUnit|  CallTypeGroup|NumberofAlarms| UnitType|Unitsequenceincalldispatch|FirePreventionDistrict| SupervisorDistrict|NeighborhoodDistrict|     Location|               RowID|\n",
      "+----------+-------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+------------+----+-----------------+--------+-------------+-------+---------------+--------------+---------+--------------------------+----------------------+-------------------+--------------------+-------------+--------------------+\n",
      "|      null|Unit ID|          null|           Call Type| Call Date|Watch Date|       Received DtTm|          Entry DtTm|       Dispatch DtTm|       Response DtTm|       On Scene DtTm|Transport DtTm|Hospital DtTm|Call Final Dispos...|      Available DtTm|             Address|         City|             null|Battalion|Station Area| Box|Original Priority|Priority|         null|   null|Call Type Group|          null|Unit Type|                      null|  Fire Prevention D...|Supervisor District|Neighborhooods - ...|        RowID|       case_location|\n",
      "| 210391607|    E19|      21017645|              Alarms|02/08/2021|02/08/2021|02/08/2021 01:00:...|02/08/2021 01:01:...|02/08/2021 01:01:...|02/08/2021 01:03:...|02/08/2021 01:05:...|          null|         null|                Fire|02/08/2021 01:18:...|400 Block of SERR...|San Francisco|            94132|      B08|          19|8581|                3|       3|            3|   true|          Alarm|             1|   ENGINE|                         1|                     8|                  7|           Lakeshore|210391607-E19|POINT (-122.48045...|\n",
      "| 210391164|    T04|      21017596|              Alarms|02/08/2021|02/08/2021|02/08/2021 10:54:...|02/08/2021 10:56:...|02/08/2021 10:56:...|02/08/2021 10:57:...|02/08/2021 10:59:...|          null|         null|                Fire|02/08/2021 11:06:...|600 Block of LONG...|San Francisco|            94158|      B03|          04|2264|                3|       3|            3|  false|          Alarm|             1|    TRUCK|                         1|                     3|                  6|         Mission Bay|210391164-T04|POINT (-122.39227...|\n",
      "| 210391034|    E16|      21017578|Citizen Assist / ...|02/08/2021|02/08/2021|02/08/2021 10:18:...|02/08/2021 10:19:...|02/08/2021 10:19:...|02/08/2021 10:20:...|02/08/2021 10:27:...|          null|         null|                Fire|02/08/2021 10:53:...|FRANKLIN ST/FILBE...|San Francisco|            94123|      B04|          16|3233|                3|       3|            3|   true|          Alarm|             1|   ENGINE|                         1|                     4|                  2|              Marina|210391034-E16|POINT (-122.42581...|\n",
      "| 210390767|    T19|      21017552|               Other|02/08/2021|02/08/2021|02/08/2021 08:50:...|02/08/2021 08:54:...|02/08/2021 08:55:...|02/08/2021 08:57:...|                null|          null|         null|                Fire|02/08/2021 09:02:...|CALL BOX: JOHN DA...|    Daly City|             null|      B09|          33|9922|                3|       3|            3|   true|           Fire|             1|    TRUCK|                         9|                  None|               None|                None|210390767-T19|POINT (-122.46239...|\n",
      "+----------+-------+--------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+--------------------+--------------------+--------------------+-------------+-----------------+---------+------------+----+-----------------+--------+-------------+-------+---------------+--------------+---------+--------------------------+----------------------+-------------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- ReceivedDtTm: string (nullable = true)\n",
      " |-- EntryDtTm: string (nullable = true)\n",
      " |-- DispatchDtTm: string (nullable = true)\n",
      " |-- ResponseDtTm: string (nullable = true)\n",
      " |-- OnSceneDtTm: string (nullable = true)\n",
      " |-- TransportDtTm: string (nullable = true)\n",
      " |-- HospitalDtTm: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ZipcodeofIncident: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumberofAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- Unitsequenceincalldispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- NeighborhoodDistrict: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(df):\n",
    "    row_num=df.count()\n",
    "    col_num=len(df.columns)\n",
    "    print(\"row numbers: %d, column numbers: %d\" % (row_num,col_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row numbers: 5500520, column numbers: 34\n",
      "CPU times: user 3.17 ms, sys: 0 ns, total: 3.17 ms\n",
      "Wall time: 6.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Marine Fire                                 |\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Lightning Strike (Investigation)            |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Train / Rail Fire                           |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|High Angle Rescue                           |\n",
      "|Structure Fire                              |\n",
      "|Industrial Accidents                        |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Fuel Spill                                  |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Train / Rail Incident                       |\n",
      "|Call Type                                   |\n",
      "+--------------------------------------------+\n",
      "\n",
      "CPU times: user 4.63 ms, sys: 548 Âµs, total: 5.18 ms\n",
      "Wall time: 9.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.select(\"CallType\").distinct().show(35,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+-------+\n",
      "|CallType                                    |count  |\n",
      "+--------------------------------------------+-------+\n",
      "|Medical Incident                            |3596332|\n",
      "|Structure Fire                              |681179 |\n",
      "|Alarms                                      |599263 |\n",
      "|Traffic Collision                           |224909 |\n",
      "|Other                                       |87468  |\n",
      "|Citizen Assist / Service Call               |82173  |\n",
      "|Outside Fire                                |68491  |\n",
      "|Water Rescue                                |28253  |\n",
      "|Vehicle Fire                                |25512  |\n",
      "|Gas Leak (Natural and LP Gases)             |22961  |\n",
      "|Electrical Hazard                           |16872  |\n",
      "|Elevator / Escalator Rescue                 |14840  |\n",
      "|Odor (Strange / Unknown)                    |12994  |\n",
      "|Smoke Investigation (Outside)               |12552  |\n",
      "|Fuel Spill                                  |6237   |\n",
      "|HazMat                                      |4200   |\n",
      "|Industrial Accidents                        |3080   |\n",
      "|Explosion                                   |2837   |\n",
      "|Aircraft Emergency                          |1511   |\n",
      "|Assist Police                               |1448   |\n",
      "|Train / Rail Incident                       |1434   |\n",
      "|High Angle Rescue                           |1275   |\n",
      "|Watercraft in Distress                      |1066   |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|783    |\n",
      "|Confined Space / Structure Collapse         |631    |\n",
      "|Mutual Aid / Assist Outside Agency          |548    |\n",
      "|Oil Spill                                   |518    |\n",
      "|Marine Fire                                 |425    |\n",
      "|Suspicious Package                          |348    |\n",
      "|Administrative                              |286    |\n",
      "|Train / Rail Fire                           |84     |\n",
      "|Lightning Strike (Investigation)            |9      |\n",
      "|Call Type                                   |1      |\n",
      "+--------------------------------------------+-------+\n",
      "\n",
      "CPU times: user 8.09 ms, sys: 0 ns, total: 8.09 ms\n",
      "Wall time: 9.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import col, asc,desc\n",
    "df.select(\"CallType\").groupBy(\"CallType\").count().orderBy(col(\"count\").desc()).show(35,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500520"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(10).createOrReplaceTempView(\"fireServiceVIEW\")\n",
    "spark.catalog.cacheTable(\"fireServiceVIEW\")\n",
    "# lazy eval, without action, table is not cached\n",
    "spark.table(\"fireServiceVIEW\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"fireServiceVIEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_df = spark.table(\"fireServiceVIEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row numbers: 5500520, column numbers: 34\n",
      "CPU times: user 2.79 ms, sys: 0 ns, total: 2.79 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_shape(cached_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cached_df.select(\"CallType\").groupBy(\"CallType\").count().orderBy(col(\"count\").desc()).show(35,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parquet_output_path=\"s3a://pengfei/sspcloud-demo/data_format/Fire_Department_Calls_for_Service.parquet\"\n",
    "df.write.mode('overwrite').parquet(parquet_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop sparksession\n",
    "spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
