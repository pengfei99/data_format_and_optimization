{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format overview\n",
    "## In this tutorial, we will overview evaluate the following data formats\n",
    "1. avro (structured)\n",
    "2. csv (semi-structured)\n",
    "3. json (semi-structured)\n",
    "4. orc (structured)\n",
    "5. parquet (structured) \n",
    "\n",
    "## We evaluate the data formats via:\n",
    "1. Disk usage\n",
    "2. Read/Write latency\n",
    "3. Random data lookup\n",
    "4. Filtering/GroupBy(column-wise)\n",
    "5. Distinct(row-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "       .builder.master(\"local[2]\") \\\n",
    "       .appName(\"Python Spark SQL basic example\") \\\n",
    "       .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.0.1\") \\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_path=\"/home/pliu/git/format-performence-test/netflix.json\"\n",
    "parquet_data_path=\"/home/pliu/git/format-performence-test/netflix.parquet\"\n",
    "avro_data_path=\"/home/pliu/git/format-performence-test/netflix.avro\"\n",
    "orc_data_path=\"/home/pliu/git/format-performence-test/netflix.orc\"\n",
    "csv_data_path=\"/home/pliu/git/format-performence-test/netflix.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful functions for evaluating data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The read function read the source data file and convert it to a spark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format_stats_path=\"../tmp/mystats.csv\"\n",
    "def write_stats(line):\n",
    "    file1 = open(data_format_stats_path,\"a\")\n",
    "    file1.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def read(fmt):\n",
    "    start = time.time()\n",
    "    if fmt == \"json\":\n",
    "        sdf = spark.read.option(\"header\", \"true\").json(json_data_path)\n",
    "    elif fmt == \"csv\":\n",
    "        sdf = spark.read.option(\"header\", \"true\").csv(csv_data_path)\n",
    "    elif fmt == \"avro\":\n",
    "        sdf = spark.read.format(\"avro\").load(avro_data_path)\n",
    "    elif fmt == \"parquet\":\n",
    "        sdf = spark.read.parquet(parquet_data_path)\n",
    "    elif fmt == \"orc\":\n",
    "        sdf = spark.read.orc(orc_data_path)\n",
    "    sdf.show(5,False)\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"read\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(stats)\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The get_shape function prints the shape(e.g. row number and column number) of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(df,fmt):\n",
    "    start = time.time()\n",
    "    row_num=df.count()\n",
    "    col_num=len(df.columns)\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"get_shape\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(\"The data frame has {} rows and {} columns\".format(row_num,col_num))\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stats function prints the min, max and numbers of a column of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(df,fmt, field=\"rating\"):\n",
    "    start = time.time()\n",
    "    max=df.agg({field: \"max\"})\n",
    "    min=df.agg({field: \"min\"})\n",
    "    count=df.agg({field: \"count\"})\n",
    "    min.show(5,False)\n",
    "    max.show(5,False)\n",
    "    count.show(5,False)\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"stats\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The random_batch function randomly select rows from the data frame. It can evaluate the ability of random data lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(df,fmt):\n",
    "    start = time.time()\n",
    "    result=df.sample(False, 0.05).collect()\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"random_batch\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(stats)\n",
    "   # return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The distinct function count distinct rows of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct(df,fmt):\n",
    "    start = time.time()\n",
    "    result = df.distinct().count()\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"distinct\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(stats)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The group_by function group and count the data frame by a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(df,fmt):\n",
    "    start = time.time()\n",
    "    result=df.groupBy(\"rating\").count()\n",
    "    result.show(5,False)\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"group_by\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(stats)\n",
    "    #return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The filtering function filter data by using a specific boolean condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(df, fmt, date=\"2005-11-15\"):\n",
    "    start = time.time()\n",
    "    result = df.filter(df.date > date).count()\n",
    "    stats=\"{}, {}, {}\".format(fmt, \"filtering\", time.time() - start)\n",
    "    write_stats(stats)\n",
    "    print(stats)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCSV(df,outputPath,fileName): Unit ={\n",
    "    df.coalesce(1).write.mode(\"overwrite\")\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\",\"false\")\n",
    "      .option(\"encoding\", \"UTF-8\")\n",
    "      .option(\"delimiter\", \",\") \n",
    "      .csv(outputPath+\"/\"+fileName)\n",
    "  }   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gathering stats of each data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get CSV format evaluation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|user_id|rating|date      |\n",
      "+-------+------+----------+\n",
      "|1488844|3     |2005-09-06|\n",
      "|822109 |5     |2005-05-13|\n",
      "|885013 |4     |2005-10-19|\n",
      "|30878  |4     |2005-12-26|\n",
      "|823519 |3     |2004-05-03|\n",
      "+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "csv, read, 4.87298059463501\n"
     ]
    }
   ],
   "source": [
    "csv_df=read(\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame has 24058262 rows and 3 columns\n",
      "csv, get_shape, 8.3622145652771\n"
     ]
    }
   ],
   "source": [
    "get_shape(csv_df,\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(rating)|\n",
      "+-----------+\n",
      "|1          |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|max(rating)|\n",
      "+-----------+\n",
      "|5          |\n",
      "+-----------+\n",
      "\n",
      "+-------------+\n",
      "|count(rating)|\n",
      "+-------------+\n",
      "|24053764     |\n",
      "+-------------+\n",
      "\n",
      "csv, stats, 26.145728588104248\n"
     ]
    }
   ],
   "source": [
    "# get min, max and row number of column rating\n",
    "stats(csv_df,\"csv\",field=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv, random_batch, 15.357799291610718\n"
     ]
    }
   ],
   "source": [
    "random_batch(csv_df,\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv, distinct, 19.20894479751587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12168704"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct(csv_df,\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|count  |\n",
      "+------+-------+\n",
      "|3     |6904181|\n",
      "|null  |4498   |\n",
      "|5     |5506583|\n",
      "|1     |1118186|\n",
      "|4     |8085741|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "csv, group_by, 8.280380249023438\n"
     ]
    }
   ],
   "source": [
    "group_by(csv_df,\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering(csv_df,\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"netflix\"\n",
    "csv_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"{}.csv\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get Json format evaluation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|date      |rating|user_id|\n",
      "+----------+------+-------+\n",
      "|2005-09-06|3     |1488844|\n",
      "|2005-05-13|5     |822109 |\n",
      "|2005-10-19|4     |885013 |\n",
      "|2005-12-26|4     |30878  |\n",
      "|2004-05-03|3     |823519 |\n",
      "+----------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "json, read, 9.966949701309204\n"
     ]
    }
   ],
   "source": [
    "json_df=read(\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shape(json_df,\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(rating)|\n",
      "+-----------+\n",
      "|1          |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|max(rating)|\n",
      "+-----------+\n",
      "|5          |\n",
      "+-----------+\n",
      "\n",
      "+-------------+\n",
      "|count(rating)|\n",
      "+-------------+\n",
      "|24053764     |\n",
      "+-------------+\n",
      "\n",
      "json, stats, 35.458019971847534\n"
     ]
    }
   ],
   "source": [
    "# get min, max and row number of column rating\n",
    "stats(json_df,\"json\",field=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json, random_batch, 17.13827896118164\n"
     ]
    }
   ],
   "source": [
    "random_batch(json_df,\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json, distinct, 21.003305673599243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12168704"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct(json_df,\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|count  |\n",
      "+------+-------+\n",
      "|3     |6904181|\n",
      "|null  |4498   |\n",
      "|5     |5506583|\n",
      "|1     |1118186|\n",
      "|4     |8085741|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "json, group_by, 12.402800798416138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[rating: string, count: bigint]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by(json_df,\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json, filtering, 11.020655632019043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "850269"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering(json_df,\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Get Avro format evaluation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|user_id|rating|date      |\n",
      "+-------+------+----------+\n",
      "|2584438|4     |2005-03-01|\n",
      "|702567 |4     |2005-03-05|\n",
      "|1253149|3     |2005-03-06|\n",
      "|321108 |4     |2005-03-08|\n",
      "|254824 |5     |2005-03-11|\n",
      "+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "avro, read, 0.18955612182617188\n"
     ]
    }
   ],
   "source": [
    "avro_df=read(\"avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame has 24058262 rows and 3 columns\n",
      "json, get_shape, 4.859561204910278\n"
     ]
    }
   ],
   "source": [
    "get_shape(avro_df,\"avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(rating)|\n",
      "+-----------+\n",
      "|1          |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|max(rating)|\n",
      "+-----------+\n",
      "|5          |\n",
      "+-----------+\n",
      "\n",
      "+-------------+\n",
      "|count(rating)|\n",
      "+-------------+\n",
      "|24053764     |\n",
      "+-------------+\n",
      "\n",
      "avro, stats, 13.65978717803955\n"
     ]
    }
   ],
   "source": [
    "stats(avro_df,\"avro\",field=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avro, random_batch, 9.225749015808105\n"
     ]
    }
   ],
   "source": [
    "random_batch(avro_df,\"avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avro, distinct, 29.572277069091797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12168704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct(avro_df,\"avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|count  |\n",
      "+------+-------+\n",
      "|3     |6904181|\n",
      "|null  |4498   |\n",
      "|5     |5506583|\n",
      "|1     |1118186|\n",
      "|4     |8085741|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "avro, group_by, 5.662991046905518\n"
     ]
    }
   ],
   "source": [
    "group_by(avro_df,\"avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avro, filtering, 4.33909010887146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "850269"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering(avro_df,\"avro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Get Parquet format evaluation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|user_id|rating|date      |\n",
      "+-------+------+----------+\n",
      "|2584438|4     |2005-03-01|\n",
      "|702567 |4     |2005-03-05|\n",
      "|1253149|3     |2005-03-06|\n",
      "|321108 |4     |2005-03-08|\n",
      "|254824 |5     |2005-03-11|\n",
      "+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "parquet, read, 0.936453104019165\n"
     ]
    }
   ],
   "source": [
    "parquet_df=read(\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame has 24058262 rows and 3 columns\n",
      "parquet, get_shape, 0.1500110626220703\n"
     ]
    }
   ],
   "source": [
    "get_shape(parquet_df,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet, random_batch, 6.159161567687988\n"
     ]
    }
   ],
   "source": [
    "random_batch(parquet_df,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(rating)|\n",
      "+-----------+\n",
      "|1          |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|max(rating)|\n",
      "+-----------+\n",
      "|5          |\n",
      "+-----------+\n",
      "\n",
      "+-------------+\n",
      "|count(rating)|\n",
      "+-------------+\n",
      "|24053764     |\n",
      "+-------------+\n",
      "\n",
      "parquet, stats, 3.7586891651153564\n"
     ]
    }
   ],
   "source": [
    "stats(parquet_df,\"parquet\",field=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet, distinct, 23.636741876602173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12168704"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct(parquet_df,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|count  |\n",
      "+------+-------+\n",
      "|3     |6904181|\n",
      "|null  |4498   |\n",
      "|5     |5506583|\n",
      "|1     |1118186|\n",
      "|4     |8085741|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "parquet, group_by, 1.2147870063781738\n"
     ]
    }
   ],
   "source": [
    "group_by(parquet_df,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet, filtering, 0.8171226978302002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "850269"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering(parquet_df,\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Get ORC format evaluation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|user_id|rating|date      |\n",
      "+-------+------+----------+\n",
      "|1488844|3     |2005-09-06|\n",
      "|822109 |5     |2005-05-13|\n",
      "|885013 |4     |2005-10-19|\n",
      "|30878  |4     |2005-12-26|\n",
      "|823519 |3     |2004-05-03|\n",
      "+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "orc, read, 2.3085367679595947\n"
     ]
    }
   ],
   "source": [
    "orc_df=read(\"orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame has 24058262 rows and 3 columns\n",
      "orc, get_shape, 1.4532253742218018\n"
     ]
    }
   ],
   "source": [
    "get_shape(orc_df,\"orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orc, random_batch, 6.4762678146362305\n"
     ]
    }
   ],
   "source": [
    "random_batch(orc_df,\"orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(rating)|\n",
      "+-----------+\n",
      "|1          |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|max(rating)|\n",
      "+-----------+\n",
      "|5          |\n",
      "+-----------+\n",
      "\n",
      "+-------------+\n",
      "|count(rating)|\n",
      "+-------------+\n",
      "|24053764     |\n",
      "+-------------+\n",
      "\n",
      "orc, stats, 4.612210035324097\n"
     ]
    }
   ],
   "source": [
    "stats(orc_df,\"orc\",field=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orc, distinct, 185.58755350112915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12168704"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct(orc_df,\"orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|count  |\n",
      "+------+-------+\n",
      "|3     |6904181|\n",
      "|null  |4498   |\n",
      "|5     |5506583|\n",
      "|1     |1118186|\n",
      "|4     |8085741|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "orc, group_by, 1.680478811264038\n"
     ]
    }
   ],
   "source": [
    "group_by(orc_df,\"orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orc, filtering, 1.186652421951294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "850269"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering(orc_df,\"orc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the stats of different format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualize the read latency for each format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+\n",
      "|format|   command|Latency(second)|\n",
      "+------+----------+---------------+\n",
      "|   csv|      read|           null|\n",
      "|   csv| get_shape|           null|\n",
      "|   csv|     stats|           null|\n",
      "|   csv|     stats|           null|\n",
      "|   csv|      read|           null|\n",
      "+------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType,StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"format\", StringType(), True),\n",
    "    StructField(\"command\", StringType(), True),\n",
    "    StructField(\"Latency(second)\", IntegerType(), True)])\n",
    "\n",
    "\n",
    "# read stats file\n",
    "rawDf=spark.read.option(\"header\", \"false\").csv(data_format_stats_path,schema=schema)\n",
    "rawDf.show(5)\n",
    "rawDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsDf=rawDf.dropDuplicates([\"format\",\"command\"])\n",
    "statsDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop sparksession\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the spark cluster is well closed. You should not see any python-spark pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                     READY   STATUS      RESTARTS   AGE\n",
      "deleting-pods-with-completed-status-1615824000-2nwxn     0/1     Completed   0          58m\n",
      "jupyter-1615800186-567f67779b-cbmgx                      1/1     Running     0          7h35m\n",
      "python-spark-sql-basic-example-6e3a6b7836d2d444-exec-1   1/1     Running     0          21s\n",
      "python-spark-sql-basic-example-6e3a6b7836d2d444-exec-2   1/1     Running     0          21s\n",
      "python-spark-sql-basic-example-6e3a6b7836d2d444-exec-3   1/1     Running     0          20s\n",
      "python-spark-sql-basic-example-6e3a6b7836d2d444-exec-4   1/1     Running     0          20s\n",
      "python-spark-sql-basic-example-6e3a6b7836d2d444-exec-5   1/1     Running     0          20s\n",
      "ubuntu-1612965548-79c9567b44-nhs9p                       1/1     Running     1          33d\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
