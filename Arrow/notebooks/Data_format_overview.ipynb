{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Arrow (Feather and IPC)\n",
    "\n",
    "## What is Arrow?\n",
    "\n",
    "Arrow is the name of an Apache project which provides:\n",
    "- data format: Feather(on disk) and IPC(in memory) data format shares the same design and architecture, which is a language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware like CPUs and GPUs. The **Arrow memory format(i.e. IPC)** also supports zero-copy reads for lightning-fast data access without serialization overhead. The **Feather** format is the on disk representation of `IPC`.\n",
    "- Libraries: Arrow's libraries implement the format and provide building blocks for a range of use cases such as (Reading/writing columnar storage formats, Sharing memory locally, Moving data over the network, In-memory data structure for analytics). It provides API in Python, R, Java, etc.\n",
    "\n",
    "## Feather\n",
    "\n",
    "Feather is a portable file format for storing Arrow tables or data frames (from languages like Python or R) that utilizes the Arrow IPC format internally. There are two file format versions for Feather:\n",
    "\n",
    "- Version 2 (V2), the default version, which is exactly represented as the Arrow IPC file format on disk. V2 files support storing all Arrow data types as well as compression with `LZ4 or ZSTD`. V2 was first made available in Apache Arrow 0.17.0.\n",
    "- Version 1 is deprecated, **Don't use it**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.feather as pf\n",
    "import sys\n",
    "import time\n",
    "import s3fs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "root_path=\"/home/pengfei/data_set/kaggle/data_format\"\n",
    "parquet_file=f\"{root_path}/netflix.parquet\"\n",
    "feather_file=f\"{root_path}/netflix.feather\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_size(file:str):\n",
    "    file_size = os.path.getsize(file) / (1024*1024)\n",
    "    print(f\"The file size of {file} is {file_size} MB\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def pandas_read_parquet_perf(parquet_file_path:str):\n",
    "    framework = \"pandas\"\n",
    "    action = \"read\"\n",
    "    dformat = \"parquet\"\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    print(df.shape)\n",
    "    stop = time.perf_counter()\n",
    "    print(df.head(5))\n",
    "    elapsed = stop - start\n",
    "    print (f\"framework: {framework} ,action: {action}, format: {dformat}, time: {elapsed}\")\n",
    "    return f\"{framework},{action},{dformat},{elapsed}\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def arrow_read_parquet_perf(parquet_file_path:str):\n",
    "    framework = \"pyarrow\"\n",
    "    action = \"read\"\n",
    "    dformat = \"parquet\"\n",
    "    start = time.perf_counter()\n",
    "    arrow_table = pq.read_table(parquet_file_path)\n",
    "    print(arrow_table.shape)\n",
    "    stop = time.perf_counter()\n",
    "    elapsed = stop - start\n",
    "    print (f\"framework: {framework} ,action: {action}, format: {dformat}, time: {elapsed}\")\n",
    "    return f\"{framework},{action},{dformat},{elapsed}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def pandas_parquet_to_feather_perf(parquet_file_path:str,feather_out_path:str):\n",
    "    framework = \"pandas\"\n",
    "    action = \"write\"\n",
    "    dformat = \"feather\"\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    print(df.head(5))\n",
    "    start = time.perf_counter()\n",
    "    df.to_feather(feather_out_path)\n",
    "    stop = time.perf_counter()\n",
    "    elapsed = stop - start\n",
    "    print (f\"framework: {framework} ,action: {action}, format: {dformat}, time: {elapsed}\")\n",
    "    return f\"{framework},{action},{dformat},{elapsed}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def pandas_read_feather_perf(feather_file_path:str):\n",
    "    framework = \"pandas\"\n",
    "    action = \"read\"\n",
    "    dformat = \"feather\"\n",
    "    start = time.perf_counter()\n",
    "    df=pd.read_feather(feather_file_path)\n",
    "    print(df.shape)\n",
    "    stop = time.perf_counter()\n",
    "    print(df.head(5))\n",
    "    elapsed = stop - start\n",
    "    print (f\"framework: {framework} ,action: {action}, format: {dformat}, time: {elapsed}\")\n",
    "    return f\"{framework},{action},{dformat},{elapsed}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def arrow_read_feather_perf(feather_file_path:str):\n",
    "    framework = \"pyarrow\"\n",
    "    action = \"read\"\n",
    "    dformat = \"feather\"\n",
    "    start = time.perf_counter()\n",
    "    arrow_table=pf.read_table(feather_file_path)\n",
    "    print(arrow_table.shape)\n",
    "    stop = time.perf_counter()\n",
    "    elapsed = stop - start\n",
    "    print (f\"framework: {framework} ,action: {action}, format: {dformat}, time: {elapsed}\")\n",
    "    return f\"{framework},{action},{dformat},{elapsed}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24058262, 3)\n",
      "   user_id rating        date\n",
      "0  1488844      3  2005-09-06\n",
      "1   822109      5  2005-05-13\n",
      "2   885013      4  2005-10-19\n",
      "3    30878      4  2005-12-26\n",
      "4   823519      3  2004-05-03\n",
      "framework: pandas ,action: read, format: parquet, time: 12.230357868014835\n"
     ]
    },
    {
     "data": {
      "text/plain": "'pandas,read,parquet,12.230357868014835'"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read parquet with pandas\n",
    "pandas_read_parquet_perf(parquet_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24058262, 3)\n",
      "framework: pyarrow ,action: read, format: parquet, time: 2.3181647080054972\n"
     ]
    },
    {
     "data": {
      "text/plain": "'pyarrow,read,parquet,2.3181647080054972'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read parquet with arrow\n",
    "arrow_read_parquet_perf(parquet_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id rating        date\n",
      "0  1488844      3  2005-09-06\n",
      "1   822109      5  2005-05-13\n",
      "2   885013      4  2005-10-19\n",
      "3    30878      4  2005-12-26\n",
      "4   823519      3  2004-05-03\n",
      "framework: pandas ,action: write, format: feather, time: 6.963145193003584\n"
     ]
    },
    {
     "data": {
      "text/plain": "'pandas,write,feather,6.963145193003584'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate feather from parquet\n",
    "pandas_parquet_to_feather_perf(parquet_file,feather_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24058262, 3)\n",
      "   user_id rating        date\n",
      "0  1488844      3  2005-09-06\n",
      "1   822109      5  2005-05-13\n",
      "2   885013      4  2005-10-19\n",
      "3    30878      4  2005-12-26\n",
      "4   823519      3  2004-05-03\n",
      "framework: pandas ,action: read, format: feather, time: 12.863280831981683\n"
     ]
    },
    {
     "data": {
      "text/plain": "'pandas,read,feather,12.863280831981683'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas read feather\n",
    "pandas_read_feather_perf(feather_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24058262, 3)\n",
      "framework: pyarrow ,action: read, format: feather, time: 1.0301093540037982\n"
     ]
    },
    {
     "data": {
      "text/plain": "'pyarrow,read,feather,1.0301093540037982'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arrow read feather\n",
    "arrow_read_feather_perf(feather_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file size of /home/pengfei/data_set/kaggle/data_format/netflix.parquet is 196.41603565216064 MB\n",
      "The file size of /home/pengfei/data_set/kaggle/data_format/netflix.feather is 523.9301090240479 MB\n"
     ]
    }
   ],
   "source": [
    "# compare the size diff\n",
    "get_size(parquet_file)\n",
    "get_size(feather_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
